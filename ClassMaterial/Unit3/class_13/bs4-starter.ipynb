{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Webscraping with BeautifulSoup and requests\n",
    "\n",
    "_Authors: Riley Daggle & Jeff Hale_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "After this lesson students will be able to:\n",
    "- Get HTML content from websites with requests \n",
    "- Parse website content with BeautifulSoup\n",
    "\n",
    "\n",
    "### Prior knowledge required\n",
    "- Python and pandas basics\n",
    "---\n",
    "\n",
    "# Web scraping issues\n",
    "\n",
    "## Terms of service ‚≠êÔ∏è\n",
    "Google is your friend. See what it says about webscraping.\n",
    "\n",
    "The law is unresolved, but generally, if the data is publicly available and you are using it for educational purposes, it's unlikely that you will have problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/scraping-legal-info.png)\n",
    "\n",
    "[Source](https://mccarthygarberlaw.com/a-comprehensive-legal-guide-to-web-scraping-in-the-us/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robots.txt ü§ñ\n",
    "\n",
    "https:my_site_name_here.com/robots.txt tells you what pages the site would like scrapers/crawlers to scrape/crawl. \n",
    "\n",
    "Read more [here](https://www.promptcloud.com/blog/how-to-read-and-respect-robots-file/#:~:text=txt%20file%20of%20a%20website%20you're%20trying%20to%20crawl,site%20are%20crawlable%20by%20bots.&text=You%20should%20steer%20clear%20from,txt.).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some scraping\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install if needed\n",
    "# pip install bs4\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import pandas, bs4, and requests\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the requests library to get the content of a sample webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs4.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rldaggie.github.io/sample-html/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did we get back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our response object has a lot more in it, we just have to get it out.\n",
    "#### Status Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status codes\n",
    "Status codes tell you how the target server responded to your request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200 = OK\n",
    "\n",
    "#### 300s = Redirection\n",
    "\n",
    "#### 400s = Client Error\n",
    "- 400 = Bad Request\n",
    "- 403 = Forbidden (not authorized)\n",
    "- 404 = Not Found\n",
    "\n",
    "#### 500s = Server Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your request was successful, you now have the contents of the webpage stored in memory on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Let's get the good stuff üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text.find('<tr>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[1747]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We could parse this by hand üòø\n",
    "\n",
    "#### But that would be painful and we can instead use a library üòÄ\n",
    "### Create a `BeautifulSoup` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>The title</title>\n",
       "<style media=\"screen\">\n",
       "      tbody tr {\n",
       "        color: red;\n",
       "      }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<h1 class=\"foobar\" id=\"title\">This is an h1</h1>\n",
       "<div>\n",
       "<h1 class=\"foobar\">This is yet another heading.</h1>\n",
       "\n",
       "      Something inside the div\n",
       "    </div>\n",
       "<h3>Todo List</h3>\n",
       "<ol class=\"todo\">\n",
       "<li class=\"foobar\">Take out trash</li>\n",
       "<li>Pay billz</li>\n",
       "<li class=\"foobar\">Feed dog</li>\n",
       "</ol>\n",
       "<h3>Completed</h3>\n",
       "<ol class=\"done\">\n",
       "<li>Mow lawn</li>\n",
       "<li class=\"foobar\"><span>Take out compost</span></li>\n",
       "<li><span>Create scraping lecture</span></li>\n",
       "</ol>\n",
       "<p class=\"foobar\">Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. <span>Duis aute irure dolor</span> in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. <em>Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum</em>.</p>\n",
       "<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. <strong><em>Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur</em></strong>. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>\n",
       "<table id=\"directory\">\n",
       "<thead>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Role</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:praveen@ga.co\">Praveen\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:fred@ga.co\">Fred\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:homer@ga.co\">Homer\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td><span class=\"foobar\">Student</span></td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:kyle@ga.co\">Kyle\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:sam@ga.co\">Sam\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:javier@ga.co\">Javier\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:nengkuan@ga.co\">Nengkuan\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:kieth@ga.co\">Kieth\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:bola@ga.co\">Bola\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:steve@ga.co\">Steve\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Student</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:nichole@ga.co\">Nichole\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Instructor</td>\n",
       "</tr>\n",
       "<tr class=\"student\">\n",
       "<th><a href=\"mailto:riley@ga.co\">Riley\n",
       "\n",
       "\n",
       "\n",
       "          </a></th>\n",
       "<td>Instructor</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<footer>\n",
       "<p>Copyright 2017. All rights reserved</p>\n",
       "<ul>\n",
       "<li><a href=\"#\">Home</a></li>\n",
       "<li><a href=\"#\">About</a></li>\n",
       "<li><a href=\"#\">Contact</a></li>\n",
       "</ul>\n",
       "</footer>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `soup.find()`\n",
    "\n",
    "### Returns either:\n",
    "\n",
    "1. A soup object of the first match\n",
    "2. `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ol class=\"todo\">\n",
       "<li class=\"foobar\">Take out trash</li>\n",
       "<li>Pay billz</li>\n",
       "<li class=\"foobar\">Feed dog</li>\n",
       "</ol>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('ol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find('ol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = soup.find('ol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the text in the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take out trash\n",
      "Pay billz\n",
      "Feed dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ol.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the attributes of the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['todo']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠êÔ∏è ‚≠êÔ∏è`soup.find_all()` ‚≠êÔ∏è ‚≠êÔ∏è\n",
    "\n",
    "### Returns a **_LIST_** (techically a bs4.element.ResultSet) of soup objects that match your query.\n",
    "\n",
    "## Behaves differently than `find()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"foobar\" id=\"title\">This is an h1</h1>,\n",
       " <h1 class=\"foobar\">This is yet another heading.</h1>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_tags = soup.find_all('h1')\n",
    "h1_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h1_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"foobar\" id=\"title\">This is an h1</h1>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h1_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an h1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_tags[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['foobar'], 'id': 'title'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1_tags[0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Make a list comprehension that creates a list containing only the text of the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List comprehension that puts the classes of the h1 tags in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['foobar'], ['foobar']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h1tag.attrs['class'] for h1tag in h1_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo List\n",
    "\n",
    "Find the ordered list items where the class = 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ol class=\"done\">\n",
       "<li>Mow lawn</li>\n",
       "<li class=\"foobar\"><span>Take out compost</span></li>\n",
       "<li><span>Create scraping lecture</span></li>\n",
       "</ol>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('ol', {'class': 'done'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = soup.find('ol', {'class': 'done'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list item texts from the ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mow lawn\n",
      "Take out compost\n",
      "Create scraping lecture\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ol.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_data = {'todos': ol.text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's scrape a beer reviews website\n",
    "\n",
    "### TOS\n",
    "\n",
    "Find the Terms of Service for the website. \n",
    "\n",
    "### robots.txt\n",
    "\n",
    "- robots.txt https:my_site_name_here.com/robots.txt tells you what pages it would like you to crawl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.beeradvocate.com/beer/trending/'\n",
    "\n",
    "beer_response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the content of any H2 tags with BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_soup = BeautifulSoup(beer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trending_table = beer_soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¬†\n",
      "Sorted by and displaying number of recent ratings.\n",
      "Ratings\n",
      "Avg\n",
      "You\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trending_table.find('tr').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab all the Trending Beers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_beers = [i.find('b').text for i in trending_table.find_all('tr')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_beer_scores = [float(i.find_all('b')[2].text) for i in trending_table.find_all('tr')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reviews =  [float(i.find_all('b')[1].text) for i in trending_table.find_all('tr')[1:]]#trending_beer_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Beer:Barrel:Time (2021)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Samuel</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Double Double Cask</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bourbon County Brand Reserve Blanton‚Äôs Stout</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Starry Noche</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Gggreennn!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>I Will Not Be Afraid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Utopias Barrel-Aged World Wide Stout</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Term Oil S'mores</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Mega Treat</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            beer  num_ratings  scores\n",
       "19                       Beer:Barrel:Time (2021)          9.0    4.79\n",
       "66                                        Samuel          5.0    4.72\n",
       "69                            Double Double Cask          5.0    4.64\n",
       "16  Bourbon County Brand Reserve Blanton‚Äôs Stout         10.0    4.62\n",
       "42                                  Starry Noche          6.0    4.57\n",
       "91                                    Gggreennn!          5.0    4.54\n",
       "65                          I Will Not Be Afraid          5.0    4.50\n",
       "10          Utopias Barrel-Aged World Wide Stout         12.0    4.43\n",
       "36                              Term Oil S'mores          6.0    4.43\n",
       "57                                    Mega Treat          6.0    4.43"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'beer': trending_beers, 'num_ratings': num_reviews, 'scores': trending_beer_scores}).nlargest(10, 'scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Issues\n",
    "Sometimes the HTML doesn't appear right away. Maybe you need to simulate clicking on buttons.\n",
    "\n",
    "You can use a headless browser. \n",
    "\n",
    "- Selenium with Chromium will do the job. Here's an article on the topic: https://www.scrapingbee.com/blog/selenium-python/\n",
    "\n",
    "- [Scrapy](https://scrapy.org/) is another option for scraping websites. It makes requests and gets data but is more powerful and complex than requests with BS4.\n",
    "\n",
    "- Your IP address (or username if logged in) can get blocked if you are deemed to be malicious. \n",
    "\n",
    "- DOS (Denial of Service) attacks are real and if you ping a website lots and lots of times quickly you might get blocked, regardless of what robots.txt or the terms of use say.\n",
    "\n",
    "- If you want to scrape repeatedly, make sure the website doesn't get changed andeaking how you grab the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've seen how to use requests with BS4 to get HTML and parse it.\n",
    "\n",
    "Scraping websites is brittle and can be frustrating. But it's pretty cool. üòâ\n",
    "\n",
    "### Check for understanding\n",
    "\n",
    "- What requests method do you use to grab HTML?\n",
    "- How do you get HTML content out of the requests object?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
